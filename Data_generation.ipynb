{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# import stuff\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "from InferSent.models import InferSent\n",
    "model_version = 1\n",
    "MODEL_PATH = \"InferSent/encoder/infersent%s.pkl\" % model_version\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': model_version}\n",
    "model = InferSent(params_model)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 100000\n"
     ]
    }
   ],
   "source": [
    "# Keep it on CPU or put it on GPU\n",
    "use_cuda = False\n",
    "model = model.cuda() if use_cuda else model\n",
    "\n",
    "# If infersent1 -> use GloVe embeddings. If infersent2 -> use InferSent embeddings.\n",
    "W2V_PATH = 'InferSent/GloVe/glove.840B.300d.txt' if model_version == 1 else 'InferSent/fastText/crawl-300d-2M.vec'\n",
    "model.set_w2v_path(W2V_PATH)\n",
    "\n",
    "# Load embeddings of K most frequent words\n",
    "model.build_vocab_k_words(K=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedSentence(text):\n",
    "    embeddings = model.encode([text], bsize=128, tokenize=True, verbose=True)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [('Other', 193203, 0),\n",
    "         ('Politics', 15734, 1),\n",
    "         ('Media', 4468, 2),\n",
    "         ('Fashion', 2270, 3),\n",
    "         ('Foreign Policy', 2205, 4),\n",
    "         ('Immigration', 1739, 5),\n",
    "         ('Economy', 1629, 6),\n",
    "         ('Health', 1434, 7),\n",
    "         ('Art', 1235, 8),\n",
    "         ('Gender', 1068, 9),\n",
    "         ('Sport', 951, 10),\n",
    "         ('Violence', 766, 11),\n",
    "         ('Climate', 574, 12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the file Other\n",
      "Nb words kept : 559704/597757 (93.6%)\n",
      "Speed : 36.7 sentences/s (cpu mode, bsize=128)\n",
      "Read the file Politics\n",
      "Nb words kept : 532875/562984 (94.7%)\n",
      "Speed : 40.1 sentences/s (cpu mode, bsize=128)\n",
      "Read the file Election\n",
      "Nb words kept : 532875/562984 (94.7%)\n",
      "Speed : 39.8 sentences/s (cpu mode, bsize=128)\n",
      "Read the file Media\n",
      "Nb words kept : 161249/171200 (94.2%)\n",
      "Speed : 33.2 sentences/s (cpu mode, bsize=128)\n",
      "Read the file Fashion\n",
      "Nb words kept : 67512/72342 (93.3%)\n",
      "Speed : 40.1 sentences/s (cpu mode, bsize=128)\n",
      "Read the file Foreign Policy\n",
      "Nb words kept : 79309/83998 (94.4%)\n",
      "Speed : 32.4 sentences/s (cpu mode, bsize=128)\n",
      "Read the file Immigration\n",
      "Nb words kept : 59314/62721 (94.6%)\n",
      "Speed : 32.5 sentences/s (cpu mode, bsize=128)\n",
      "Read the file Economy\n",
      "Nb words kept : 56716/59850 (94.8%)\n",
      "Speed : 31.6 sentences/s (cpu mode, bsize=128)\n",
      "Read the file Health\n",
      "Nb words kept : 47073/49346 (95.4%)\n",
      "Speed : 32.2 sentences/s (cpu mode, bsize=128)\n",
      "Read the file Art\n",
      "Nb words kept : 43081/45782 (94.1%)\n",
      "Speed : 31.0 sentences/s (cpu mode, bsize=128)\n",
      "Read the file Gender\n",
      "Nb words kept : 34263/36301 (94.4%)\n",
      "Speed : 32.4 sentences/s (cpu mode, bsize=128)\n",
      "Read the file Sport\n",
      "Nb words kept : 34189/36335 (94.1%)\n",
      "Speed : 29.2 sentences/s (cpu mode, bsize=128)\n",
      "Read the file Violence\n",
      "Nb words kept : 26028/27423 (94.9%)\n",
      "Speed : 31.3 sentences/s (cpu mode, bsize=128)\n",
      "Read the file Climate\n",
      "Nb words kept : 19876/20879 (95.2%)\n",
      "Speed : 29.1 sentences/s (cpu mode, bsize=128)\n"
     ]
    }
   ],
   "source": [
    "for name, size, idx in names:\n",
    "    file = open('data/%s.txt'%name, 'r')\n",
    "    if name == 'Other':\n",
    "        lines = []\n",
    "        for line in file:\n",
    "            if np.random.rand() < 0.08:\n",
    "                lines.append(line)\n",
    "    else:\n",
    "        lines = file.readlines()\n",
    "    print(\"Read the file %s\"%name)\n",
    "    embed = model.encode(lines, bsize=128, tokenize=True, verbose=True)\n",
    "    results = np.zeros((embed.shape[0], embed.shape[1] + 1))\n",
    "    results[:, :4096] = embed\n",
    "    results[:, -1] = idx\n",
    "    np.save('data/np_array/%s.npy'%name, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/np_array/Other.npy')\n",
    "for name, size, idx in names:\n",
    "    if name == 'Election':\n",
    "        continue\n",
    "    if name == 'Other':\n",
    "        continue\n",
    "    else:\n",
    "        data = np.concatenate([data, np.load('data/np_array/%s.npy'%name)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction only once\n",
    "# for i in range(49603):\n",
    "#     if data[i, -1] > 2:\n",
    "#         data[i, -1] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the data\n",
    "np.random.shuffle(data)\n",
    "np.save('data/np_array/all.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
